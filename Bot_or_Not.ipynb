{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "552f4b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv('/Users/samuelhosmer/Downloads/facebook-recruiting-iv-human-or-bot/train.csv')\n",
    "df_bids = pd.read_csv('/Users/samuelhosmer/Downloads/facebook-recruiting-iv-human-or-bot/bids.csv') #add data to git?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10c9eab",
   "metadata": {},
   "source": [
    "We take on the kaggle classification competition Human or Robot, which was hosted by Facebook in 2014. We are given two tabular datasets, one containing labels, and another containing potential features. The goal is to produce an algorithm that can faithfully discern the difference in bidding activity between humans and bots.\n",
    "\n",
    "https://www.kaggle.com/c/facebook-recruiting-iv-human-or-bot/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56e3f948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2013 entries, 0 to 2012\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   bidder_id        2013 non-null   object \n",
      " 1   payment_account  2013 non-null   object \n",
      " 2   address          2013 non-null   object \n",
      " 3   outcome          2013 non-null   float64\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 63.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4ec5572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7656334 entries, 0 to 7656333\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Dtype \n",
      "---  ------       ----- \n",
      " 0   bid_id       int64 \n",
      " 1   bidder_id    object\n",
      " 2   auction      object\n",
      " 3   merchandise  object\n",
      " 4   device       object\n",
      " 5   time         int64 \n",
      " 6   country      object\n",
      " 7   ip           object\n",
      " 8   url          object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 525.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_bids.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653f32eb",
   "metadata": {},
   "source": [
    "As we can see , we have a very small labeled data-set. Nevertheless we will serve it to an ML algorithm by first reducing noise via some feature engineering.\n",
    "\n",
    "To begin we sort the dataset for each bidder via the time of their bids. We then compute successive time differences between bids and add this as an intermediate column, from which we will generate new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34431452",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_bids.sort_values(['bidder_id','time'])\n",
    "df['difference']=df.groupby('bidder_id')['time'].diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f80d2d",
   "metadata": {},
   "source": [
    "Now to build some sensible features to feed an algorthim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da732576",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_dif = df.groupby('bidder_id')['difference'].mean().reset_index().rename(columns={'difference':'avg_diff'}) \n",
    "\n",
    "df_min_dif = df.groupby('bidder_id')['difference'].min().reset_index().rename(columns={'difference':'min_diff'})\n",
    "\n",
    "df_var_dif = df.groupby('bidder_id')['difference'].var().reset_index().rename(columns={'difference':'var_diff'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d46c595",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_de = df.groupby('bidder_id')['device'].nunique().reset_index().rename(columns={'device':'unique_devices'})\n",
    "\n",
    "df_ip = df.groupby('bidder_id')['ip'].nunique().reset_index().rename(columns={'ip':'ip_count'})\n",
    "\n",
    "df_ur = df.groupby('bidder_id')['url'].nunique().reset_index().rename(columns={'url':'url_count'})\n",
    "\n",
    "df_au = df.groupby('bidder_id')['auction'].nunique().reset_index().rename(columns={'auction':'auc_count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bfa710",
   "metadata": {},
   "source": [
    "Inspecting the data, some promising categorical features are Merchandise and Country. We write a simple function returning a comma separated string containing the 10 most frequent items in a given list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7940d561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "def ten_mc(lst):\n",
    "    cnt = Counter(lst)\n",
    "    mc = np.array(cnt.most_common(10))\n",
    "    s = ','.join(mc[:,0]) # s = np.array(mc[:,0], dtype=np.str)                \n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0270f43d",
   "metadata": {},
   "source": [
    "We then apply our ten_mc function to obtain the 10 most common merchandises and countries for each bidder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fff07459",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_me = df.groupby('bidder_id')['merchandise'].apply(ten_mc).reset_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ff2e15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6614 entries, 0 to 6613\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   bidder_id    6614 non-null   object\n",
      " 1   merchandise  6614 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 103.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_me.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca3a9d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6615"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_me['merchandise'].apply(lambda x: len(x.split(','))).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8340d33f",
   "metadata": {},
   "source": [
    "It turns out there's only 1 recorded type of merchandise for all but 1 bidder, which is odd and inconvenient.\n",
    "Thankfully this isn't the case for the country feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f19047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country'] = df['country'].astype(str)\n",
    "df_ct = df.groupby('bidder_id')['country'].apply(ten_mc).reset_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c14f17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6614 entries, 0 to 6613\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   bidder_id  6614 non-null   object\n",
      " 1   country    6614 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 103.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_ct.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b49fd5",
   "metadata": {},
   "source": [
    "We also engineer some features to inspect how bidders behave within a given auction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a34bd775",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vtpa = df.groupby(by = ['bidder_id','auction'])['time'].var().reset_index() \n",
    "df_vtpa = df_vtpa.groupby('bidder_id')['time'].median().reset_index().rename(columns = {'time':'med_var_time_per_auc'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "241accac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_med_avg_dpa = df.groupby(by=['bidder_id','auction'])['difference'].mean().reset_index() \n",
    "df_med_avg_dpa = df_med_avg_dpa.rename(columns={'difference':'med_avg_dif_per_auc'})\n",
    "df_med_avg_dpa = df_med_avg_dpa.groupby('bidder_id')['med_avg_dif_per_auc'].median().reset_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "050ab5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_med_min_dpa = df.groupby(by=['bidder_id','auction'])['difference'].min().reset_index()\n",
    "df_med_min_dpa = df_med_min_dpa.rename(columns={'difference':'med_min_dif_per_auc'})\n",
    "df_med_min_dpa = df_med_min_dpa.groupby('bidder_id')['med_min_dif_per_auc'].median().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "497ffcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aupa = df.groupby(by=['bidder_id','auction'])['url'].nunique().reset_index()\n",
    "df_aupa = df_aupa.rename(columns={'url':'avg_url_per_auc'})\n",
    "df_aupa = df_aupa.groupby('bidder_id')['avg_url_per_auc'].mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3d4aa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adpa = df.groupby(by=['bidder_id','auction'])['device'].nunique().reset_index()\n",
    "df_adpa = df_adpa.rename(columns={'device':'med_avg_dev_per_auc'})\n",
    "df_adpa = df_adpa.groupby('bidder_id')['med_avg_dev_per_auc'].median().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a59893ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_bid_per_auc = df.groupby(by=['bidder_id','auction'])['bid_id'].count().reset_index()\n",
    "df_avg_bid_per_auc = df_avg_bid_per_auc.rename(columns={'bid_id':'avg_bid_per_auc'})\n",
    "df_avg_bid_per_auc = df_avg_bid_per_auc.groupby('bidder_id')['avg_bid_per_auc'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b07e5004",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_per_auc = df.groupby(by = ['bidder_id','auction'])['ip'].nunique().reset_index()\n",
    "ip_per_auc = ip_per_auc.drop(columns = ['auction'])\n",
    "df_ic = ip_per_auc.groupby('bidder_id')['ip'].mean().reset_index().rename(columns = {'ip':'avg_ip_per_auc'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66eed930",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = df_train.set_index('bidder_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f19e0dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df_min_dif, df_avg_dif, df_med_min_dpa, df_med_avg_dpa, df_vtpa, df_avg_bid_per_auc, df_ip, df_ur, \n",
    "       df_ct, df_de, df_me, df_au, df_ic, df_aupa, df_adpa, df_var_dif]\n",
    "\n",
    "for j in dfs:\n",
    "    dff = dff.merge(j, how = 'left', on = 'bidder_id')\n",
    "dft = dff.set_index('bidder_id').copy()\n",
    "dft = dft.replace({pd.NA: np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5de29515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "      <th>min_diff</th>\n",
       "      <th>avg_diff</th>\n",
       "      <th>med_min_dif_per_auc</th>\n",
       "      <th>med_avg_dif_per_auc</th>\n",
       "      <th>med_var_time_per_auc</th>\n",
       "      <th>avg_bid_per_auc</th>\n",
       "      <th>ip_count</th>\n",
       "      <th>url_count</th>\n",
       "      <th>unique_devices</th>\n",
       "      <th>auc_count</th>\n",
       "      <th>avg_ip_per_auc</th>\n",
       "      <th>avg_url_per_auc</th>\n",
       "      <th>med_avg_dev_per_auc</th>\n",
       "      <th>var_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>103.0</td>\n",
       "      <td>9.800000e+01</td>\n",
       "      <td>9.800000e+01</td>\n",
       "      <td>9.800000e+01</td>\n",
       "      <td>9.800000e+01</td>\n",
       "      <td>9.800000e+01</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>9.800000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.002148e+07</td>\n",
       "      <td>5.332332e+10</td>\n",
       "      <td>2.510499e+10</td>\n",
       "      <td>3.639958e+10</td>\n",
       "      <td>6.745955e+24</td>\n",
       "      <td>23.154672</td>\n",
       "      <td>2387.796117</td>\n",
       "      <td>544.582524</td>\n",
       "      <td>163.611650</td>\n",
       "      <td>145.038835</td>\n",
       "      <td>12.062625</td>\n",
       "      <td>6.308186</td>\n",
       "      <td>1.844660</td>\n",
       "      <td>9.075986e+23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.607234e+08</td>\n",
       "      <td>1.606725e+11</td>\n",
       "      <td>2.029400e+11</td>\n",
       "      <td>2.172848e+11</td>\n",
       "      <td>9.595151e+24</td>\n",
       "      <td>42.999725</td>\n",
       "      <td>11269.674137</td>\n",
       "      <td>1163.909786</td>\n",
       "      <td>222.811854</td>\n",
       "      <td>195.103186</td>\n",
       "      <td>26.301128</td>\n",
       "      <td>11.697261</td>\n",
       "      <td>1.895595</td>\n",
       "      <td>2.496103e+24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.928230e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.911544e+07</td>\n",
       "      <td>2.751016e+19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.472533e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.556730e+09</td>\n",
       "      <td>1.052632e+08</td>\n",
       "      <td>8.894312e+08</td>\n",
       "      <td>7.781177e+23</td>\n",
       "      <td>6.753145</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>2.249042</td>\n",
       "      <td>1.234326</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.905921e+20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.874925e+10</td>\n",
       "      <td>1.184211e+09</td>\n",
       "      <td>6.427769e+09</td>\n",
       "      <td>5.089716e+24</td>\n",
       "      <td>11.863014</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>5.890000</td>\n",
       "      <td>3.432271</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.726600e+22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.651844e+10</td>\n",
       "      <td>3.190789e+09</td>\n",
       "      <td>1.514474e+10</td>\n",
       "      <td>1.044141e+25</td>\n",
       "      <td>22.253428</td>\n",
       "      <td>1089.000000</td>\n",
       "      <td>591.000000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>170.500000</td>\n",
       "      <td>11.909535</td>\n",
       "      <td>8.292066</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.148890e+23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.052632e+09</td>\n",
       "      <td>1.516000e+12</td>\n",
       "      <td>2.007868e+12</td>\n",
       "      <td>2.140171e+12</td>\n",
       "      <td>8.198439e+25</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>111918.000000</td>\n",
       "      <td>8551.000000</td>\n",
       "      <td>1144.000000</td>\n",
       "      <td>1018.000000</td>\n",
       "      <td>212.714286</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.853533e+25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       outcome      min_diff      avg_diff  med_min_dif_per_auc  \\\n",
       "count    103.0  9.800000e+01  9.800000e+01         9.800000e+01   \n",
       "mean       1.0  8.002148e+07  5.332332e+10         2.510499e+10   \n",
       "std        0.0  3.607234e+08  1.606725e+11         2.029400e+11   \n",
       "min        1.0  0.000000e+00  9.928230e+07         0.000000e+00   \n",
       "25%        1.0  0.000000e+00  5.556730e+09         1.052632e+08   \n",
       "50%        1.0  0.000000e+00  1.874925e+10         1.184211e+09   \n",
       "75%        1.0  0.000000e+00  4.651844e+10         3.190789e+09   \n",
       "max        1.0  3.052632e+09  1.516000e+12         2.007868e+12   \n",
       "\n",
       "       med_avg_dif_per_auc  med_var_time_per_auc  avg_bid_per_auc  \\\n",
       "count         9.800000e+01          9.800000e+01       103.000000   \n",
       "mean          3.639958e+10          6.745955e+24        23.154672   \n",
       "std           2.172848e+11          9.595151e+24        42.999725   \n",
       "min           9.911544e+07          2.751016e+19         1.000000   \n",
       "25%           8.894312e+08          7.781177e+23         6.753145   \n",
       "50%           6.427769e+09          5.089716e+24        11.863014   \n",
       "75%           1.514474e+10          1.044141e+25        22.253428   \n",
       "max           2.140171e+12          8.198439e+25       325.000000   \n",
       "\n",
       "            ip_count    url_count  unique_devices    auc_count  \\\n",
       "count     103.000000   103.000000      103.000000   103.000000   \n",
       "mean     2387.796117   544.582524      163.611650   145.038835   \n",
       "std     11269.674137  1163.909786      222.811854   195.103186   \n",
       "min         1.000000     1.000000        1.000000     1.000000   \n",
       "25%        34.000000     4.500000        4.500000    23.000000   \n",
       "50%       290.000000    88.000000       78.000000    74.000000   \n",
       "75%      1089.000000   591.000000      219.000000   170.500000   \n",
       "max    111918.000000  8551.000000     1144.000000  1018.000000   \n",
       "\n",
       "       avg_ip_per_auc  avg_url_per_auc  med_avg_dev_per_auc      var_diff  \n",
       "count      103.000000       103.000000           103.000000  9.800000e+01  \n",
       "mean        12.062625         6.308186             1.844660  9.075986e+23  \n",
       "std         26.301128        11.697261             1.895595  2.496103e+24  \n",
       "min          1.000000         1.000000             1.000000  5.472533e+15  \n",
       "25%          2.249042         1.234326             1.000000  4.905921e+20  \n",
       "50%          5.890000         3.432271             1.000000  1.726600e+22  \n",
       "75%         11.909535         8.292066             2.000000  4.148890e+23  \n",
       "max        212.714286       109.000000            15.000000  1.853533e+25  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft[dft['outcome']==1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4355aad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "      <th>min_diff</th>\n",
       "      <th>avg_diff</th>\n",
       "      <th>med_min_dif_per_auc</th>\n",
       "      <th>med_avg_dif_per_auc</th>\n",
       "      <th>med_var_time_per_auc</th>\n",
       "      <th>avg_bid_per_auc</th>\n",
       "      <th>ip_count</th>\n",
       "      <th>url_count</th>\n",
       "      <th>unique_devices</th>\n",
       "      <th>auc_count</th>\n",
       "      <th>avg_ip_per_auc</th>\n",
       "      <th>avg_url_per_auc</th>\n",
       "      <th>med_avg_dev_per_auc</th>\n",
       "      <th>var_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1910.0</td>\n",
       "      <td>1.584000e+03</td>\n",
       "      <td>1.584000e+03</td>\n",
       "      <td>1.584000e+03</td>\n",
       "      <td>1.584000e+03</td>\n",
       "      <td>1.319000e+03</td>\n",
       "      <td>1881.000000</td>\n",
       "      <td>1881.000000</td>\n",
       "      <td>1881.000000</td>\n",
       "      <td>1881.000000</td>\n",
       "      <td>1881.000000</td>\n",
       "      <td>1881.000000</td>\n",
       "      <td>1881.000000</td>\n",
       "      <td>1881.000000</td>\n",
       "      <td>1.438000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.180262e+12</td>\n",
       "      <td>3.395101e+12</td>\n",
       "      <td>1.884196e+12</td>\n",
       "      <td>2.290625e+12</td>\n",
       "      <td>1.156370e+26</td>\n",
       "      <td>6.441525</td>\n",
       "      <td>581.256247</td>\n",
       "      <td>335.187135</td>\n",
       "      <td>73.947368</td>\n",
       "      <td>58.070707</td>\n",
       "      <td>4.422164</td>\n",
       "      <td>2.666974</td>\n",
       "      <td>1.481393</td>\n",
       "      <td>1.009949e+26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.993803e+12</td>\n",
       "      <td>8.378402e+12</td>\n",
       "      <td>7.605833e+12</td>\n",
       "      <td>7.935211e+12</td>\n",
       "      <td>3.610681e+26</td>\n",
       "      <td>29.986961</td>\n",
       "      <td>4140.678180</td>\n",
       "      <td>2735.527301</td>\n",
       "      <td>184.560908</td>\n",
       "      <td>142.933476</td>\n",
       "      <td>24.201059</td>\n",
       "      <td>6.301742</td>\n",
       "      <td>3.110539</td>\n",
       "      <td>2.727733e+26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.084343e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.265664e+07</td>\n",
       "      <td>1.385042e+15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.385042e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.263158e+07</td>\n",
       "      <td>1.009170e+11</td>\n",
       "      <td>8.315789e+09</td>\n",
       "      <td>3.523136e+10</td>\n",
       "      <td>3.250935e+24</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.453019e+23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.894737e+08</td>\n",
       "      <td>7.090506e+11</td>\n",
       "      <td>9.194737e+10</td>\n",
       "      <td>2.327895e+11</td>\n",
       "      <td>9.192128e+24</td>\n",
       "      <td>1.610390</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>1.172414</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.122420e+24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.722368e+10</td>\n",
       "      <td>2.763599e+12</td>\n",
       "      <td>8.698158e+11</td>\n",
       "      <td>1.372539e+12</td>\n",
       "      <td>1.668084e+25</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.398833e+25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.610295e+13</td>\n",
       "      <td>7.610295e+13</td>\n",
       "      <td>7.610295e+13</td>\n",
       "      <td>7.610295e+13</td>\n",
       "      <td>2.590265e+27</td>\n",
       "      <td>1023.500000</td>\n",
       "      <td>109159.000000</td>\n",
       "      <td>81376.000000</td>\n",
       "      <td>2618.000000</td>\n",
       "      <td>1623.000000</td>\n",
       "      <td>980.000000</td>\n",
       "      <td>129.166667</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>2.377356e+27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       outcome      min_diff      avg_diff  med_min_dif_per_auc  \\\n",
       "count   1910.0  1.584000e+03  1.584000e+03         1.584000e+03   \n",
       "mean       0.0  1.180262e+12  3.395101e+12         1.884196e+12   \n",
       "std        0.0  6.993803e+12  8.378402e+12         7.605833e+12   \n",
       "min        0.0  0.000000e+00  7.084343e+07         0.000000e+00   \n",
       "25%        0.0  5.263158e+07  1.009170e+11         8.315789e+09   \n",
       "50%        0.0  7.894737e+08  7.090506e+11         9.194737e+10   \n",
       "75%        0.0  2.722368e+10  2.763599e+12         8.698158e+11   \n",
       "max        0.0  7.610295e+13  7.610295e+13         7.610295e+13   \n",
       "\n",
       "       med_avg_dif_per_auc  med_var_time_per_auc  avg_bid_per_auc  \\\n",
       "count         1.584000e+03          1.319000e+03      1881.000000   \n",
       "mean          2.290625e+12          1.156370e+26         6.441525   \n",
       "std           7.935211e+12          3.610681e+26        29.986961   \n",
       "min           6.265664e+07          1.385042e+15         1.000000   \n",
       "25%           3.523136e+10          3.250935e+24         1.000000   \n",
       "50%           2.327895e+11          9.192128e+24         1.610390   \n",
       "75%           1.372539e+12          1.668084e+25         3.750000   \n",
       "max           7.610295e+13          2.590265e+27      1023.500000   \n",
       "\n",
       "            ip_count     url_count  unique_devices    auc_count  \\\n",
       "count    1881.000000   1881.000000     1881.000000  1881.000000   \n",
       "mean      581.256247    335.187135       73.947368    58.070707   \n",
       "std      4140.678180   2735.527301      184.560908   142.933476   \n",
       "min         1.000000      1.000000        1.000000     1.000000   \n",
       "25%         2.000000      1.000000        2.000000     2.000000   \n",
       "50%        11.000000      4.000000        8.000000     9.000000   \n",
       "75%        88.000000     34.000000       52.000000    41.000000   \n",
       "max    109159.000000  81376.000000     2618.000000  1623.000000   \n",
       "\n",
       "       avg_ip_per_auc  avg_url_per_auc  med_avg_dev_per_auc      var_diff  \n",
       "count     1881.000000      1881.000000          1881.000000  1.438000e+03  \n",
       "mean         4.422164         2.666974             1.481393  1.009949e+26  \n",
       "std         24.201059         6.301742             3.110539  2.727733e+26  \n",
       "min          1.000000         1.000000             1.000000  1.385042e+15  \n",
       "25%          1.000000         1.000000             1.000000  1.453019e+23  \n",
       "50%          1.400000         1.172414             1.000000  2.122420e+24  \n",
       "75%          3.000000         2.000000             1.000000  3.398833e+25  \n",
       "max        980.000000       129.166667            82.000000  2.377356e+27  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft[dft['outcome']==0].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560613fc",
   "metadata": {},
   "source": [
    "From the above statistical descriptions of our features by label, we choose the most promising features as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a44cd42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feat_nms = [ 'ip_count','avg_bid_per_auc','avg_ip_per_auc',\n",
    "                'med_min_dif_per_auc', 'med_avg_dif_per_auc',\n",
    "                 'med_var_time_per_auc','auc_count','avg_diff',\n",
    "                'min_diff', 'var_diff','unique_devices']   \n",
    "                                              \n",
    "cat_feat_nms = ['country'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48a037bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = dft[cat_feat_nms + num_feat_nms ]\n",
    "y_train = dft[\"outcome\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b86ea0",
   "metadata": {},
   "source": [
    "In order to feed the 'Country' data to an algorithm in SciKitLearn, we first implement the following custom preprocessing transformation. The idea is to convert each country to a unit coordinate vector in R^d, where d is the number of countries in our data. We then take the top 10 countries for each bidder and sum the corresponding coordinate vectors. We acomplish this with CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb12fffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "country_ix = x_train.columns.get_loc(\"country\")\n",
    "\n",
    "class CountVectPre(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        tmp = X[:,country_ix]\n",
    "        vec = CountVectorizer()\n",
    "        x=vec.fit_transform(tmp).astype('float32')\n",
    "        return np.c_[np.delete(X,country_ix,1),x.toarray()].astype('float32') \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c891f5c8",
   "metadata": {},
   "source": [
    "Now we're ready to build a preprocessing/cleaning pipeline to feed in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2175a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
    "        (\"cat_encoder\", CountVectPre()) \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8b12a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "full_pipe = ColumnTransformer([\n",
    "            (\"cat\",cat_pipe,cat_feat_nms),\n",
    "            (\"num\",num_pipe,num_feat_nms)\n",
    "            \n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "699826bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = full_pipe.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37ea495a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9290361732508329\n",
      "0.047423782060115646\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "fc = RandomForestClassifier(max_features=\"sqrt\",random_state=1)\n",
    "fc.fit(x_train,y_train)\n",
    "\n",
    "score_fc = cross_val_score(fc, x_train, y_train, cv=kfold, scoring=\"roc_auc\")\n",
    "print(score_fc.mean()) #.9265 before change .mean() to .median()\n",
    "print(score_fc.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b117988c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 400, 'max_features': 5, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "param_space_fc = {'criterion':['gini','entropy'], 'max_features': np.arange(1,13,2),\n",
    "                  'n_estimators': [300,400,500]}\n",
    "\n",
    "rnd_srch_fc = RandomizedSearchCV(fc, param_space_fc, cv=kfold, n_iter=30,\n",
    "                                 scoring=\"roc_auc\", verbose=0) #set verbose=3 to inspect\n",
    "rnd_srch_fc.fit(x_train,y_train)\n",
    "\n",
    "print(rnd_srch_fc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc3193ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9334316991908616\n",
      "0.03870021426063308\n"
     ]
    }
   ],
   "source": [
    "fcb = rnd_srch_fc.best_estimator_\n",
    "fcb.fit(x_train,y_train)\n",
    "#{'n_estimators': 400, 'max_features': 5, 'criterion': 'entropy'}\n",
    "\n",
    "score_fcb = cross_val_score(fcb, x_train, y_train, cv=kfold, scoring=\"roc_auc\")\n",
    "print(score_fcb.mean()) #0.93326 before change in features\n",
    "print(score_fcb.std()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129f51d8",
   "metadata": {},
   "source": [
    "And just like that, we're in the top 50 on the leaderboard of the Kaggle competition. Well within the top 10% of all participants that achived scores above the sample submission benchmark (0.5 ROC_AUC)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf95eef4",
   "metadata": {},
   "source": [
    "Instead of improving this model to attain a potentially higher score, let's test drive a Multilayer Perceptron or Neural net, on the task.\n",
    "\n",
    "Neural nets are universal approximators of continuous functions on the n-disk \n",
    "\n",
    "[cf. Hornik, Kurt. 1990. https://www.sciencedirect.com/science/article/abs/pii/089360809190009T],\n",
    "\n",
    "\n",
    "and are very well suited to classification tasks. To test one, or lots, we use SciKeras, a Keras wrapper to utilize the model selection functionality of Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88c2cb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import warnings\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "warnings.filterwarnings(\"ignore\", message=\"Setting the random state for TF\")\n",
    "\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d16212c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_net(n_hidden,n_nodes,dropout,meta):\n",
    "    n_features_in_ = meta[\"n_features_in_\"]\n",
    "    n_classes_ = meta[\"n_classes_\"]\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(layers.Input(shape=(n_features_in_,)))\n",
    "    for k in range(n_hidden):\n",
    "        model.add(layers.Dense(n_nodes, activation=\"relu\"))\n",
    "    model.add(layers.Dropout(dropout))\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2429f82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-27 14:42:35.360294: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KerasClassifier(\n",
       "\tmodel=<function clf_net at 0x186fb45f0>\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=1\n",
       "\toptimizer=adam\n",
       "\tloss=binary_crossentropy\n",
       "\tmetrics=AUC\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=0\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=30\n",
       "\toptimizer__learning_rate=0.008\n",
       "\tn_hidden=1\n",
       "\tn_nodes=128\n",
       "\tdropout=0.3\n",
       "\tclass_weight=None\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "kc = KerasClassifier(model=clf_net,\n",
    "                     optimizer=\"adam\",\n",
    "                     optimizer__learning_rate=8e-3,\n",
    "                     loss=\"binary_crossentropy\",\n",
    "                     n_hidden=1,\n",
    "                     n_nodes=128,\n",
    "                     dropout=0.3,\n",
    "                     metrics=\"AUC\",\n",
    "                     epochs=30,\n",
    "                     verbose =0, #\n",
    "                     random_state=1\n",
    "                    )\n",
    "\n",
    "kc.fit(x_train,y_train,verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "958389a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8003331746787244\n",
      "0.05265215029050663\n"
     ]
    }
   ],
   "source": [
    "score_kc = cross_val_score(kc, x_train, y_train, cv=kfold, scoring=\"roc_auc\")\n",
    "\n",
    "print(score_kc.mean()) \n",
    "print(score_kc.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af335ef8",
   "metadata": {},
   "source": [
    "This is not terrible, but underwhelming. Neural networks are famously finicky. Perhaps we can find the right hyperparameters and get some positive movement on the score. As the data is fairly imbalanced, we can modify the class_weights argument in an attempt to balance the data without resampling. [c.f. https://keras.io/examples/structured_data/imbalanced_classification/] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18cb6e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = y_train.sum() #103\n",
    "neg = len(y_train) - y_train.sum() #1910\n",
    "weight_for_0 = 1\n",
    "weight_for_1 = neg//pos\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4aa6084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=10, random_state=1, shuffle=True),\n",
       "                   estimator=KerasClassifier(dropout=0.3, epochs=30, loss='binary_crossentropy', metrics='AUC', model=<function clf_net at 0x186fb45f0>, n_hidden=1, n_nodes=128, optimizer='adam', optimizer__learning_rate=0.008, random_state=1, verbose=0),\n",
       "                   n_iter=30,\n",
       "                   param_distributions={'class_weight': [N...\n",
       "       7.33779454e-02, 4.61692974e-02, 9.31301057e-02, 1.72780364e-01,\n",
       "       1.98383737e-01, 2.69408367e-01, 2.09597257e-01, 3.42609750e-01,\n",
       "       1.02226125e-01, 4.39058718e-01, 1.36937966e-02, 3.35233755e-01,\n",
       "       2.08652401e-01, 2.79344914e-01, 7.01934693e-02, 9.90507445e-02]),\n",
       "                                        'n_hidden': [1, 2, 3],\n",
       "                                        'n_nodes': [32, 64, 128],\n",
       "                                        'optimizer__learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x187e7a910>},\n",
       "                   scoring='roc_auc')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from scipy.stats import reciprocal\n",
    "\n",
    "param_space_kc = { \"n_hidden\": [1,2,3], \"n_nodes\": [32,64,128],\n",
    "                   \"dropout\": np.random.uniform(0,0.5, 20),\n",
    "                   \"optimizer__learning_rate\": reciprocal(1e-5,1e-1),\n",
    "                   \"class_weight\": [None, class_weight]\n",
    "              }\n",
    "              \n",
    "rnd_srch_kc = RandomizedSearchCV(kc, param_space_kc, n_iter=30, \n",
    "                                 cv=kfold, scoring=\"roc_auc\",\n",
    "                                 verbose=0\n",
    "                                ) \n",
    "\n",
    "                                 \n",
    "rnd_srch_kc.fit(x_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38e8d8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': None, 'dropout': 0.34260975019837975, 'n_hidden': 1, 'n_nodes': 128, 'optimizer__learning_rate': 0.00038967931033848135}\n"
     ]
    }
   ],
   "source": [
    "print(rnd_srch_kc.best_params_) #show best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e55bca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KerasClassifier(\n",
       "\tmodel=<function clf_net at 0x186fb45f0>\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=1\n",
       "\toptimizer=adam\n",
       "\tloss=binary_crossentropy\n",
       "\tmetrics=AUC\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=0\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=30\n",
       "\toptimizer__learning_rate=0.00038967931033848135\n",
       "\tn_hidden=1\n",
       "\tn_nodes=128\n",
       "\tdropout=0.34260975019837975\n",
       "\tclass_weight=None\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kcb = rnd_srch_kc.best_estimator_\n",
    "kcb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3224e800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8570918610185625\n",
      "0.05885763081323874\n"
     ]
    }
   ],
   "source": [
    "score_kcb = cross_val_score(kcb, x_train, y_train, cv=kfold, scoring=\"roc_auc\")\n",
    "#predict_kcb = cross_val_predict(kcb, x_train, y_train, cv=kfold, method=\"predict_proba\")\n",
    "\n",
    "print(score_kcb.mean()) #.8624 #'n_nodes': 232, 'n_hidden': 2, 'lrn_rate': 0.009133769442335437, 'drp_rt': 0.39647750153506484\n",
    "print(score_kcb.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51510d1",
   "metadata": {},
   "source": [
    "Not as much improvement as we would have hoped for. Our Neural Net still is lagging far behind the bagged trees, and well below the median score of participants that scored above the sample submission benchmark.\n",
    "\n",
    "Perhaps Neural Networks have a bias problem in the setting of small imbalanced tabular data sets-- this is something to think about."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8949f9",
   "metadata": {},
   "source": [
    "We finish by checking if the most famous boosting algorithm can come reasonably close to the most famous bagging one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c3f22de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.905233222275107\n",
      "0.05798335083042643\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gc = GradientBoostingClassifier(n_estimators=200, random_state=1)\n",
    "gc.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "score_gc = cross_val_score(gc,x_train,y_train,cv=kfold,scoring='roc_auc')\n",
    "print(score_gc.mean()) \n",
    "print(score_gc.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0497f5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=10, random_state=1, shuffle=True),\n",
       "                   estimator=GradientBoostingClassifier(n_estimators=200,\n",
       "                                                        random_state=1),\n",
       "                   n_iter=30,\n",
       "                   param_distributions={'learning_rate': array([0.        , 0.00526316, 0.01052632, 0.01578947, 0.02105263,\n",
       "       0.02631579, 0.03157895, 0.03684211, 0.04210526, 0.04736842,\n",
       "       0.05263158, 0.05789474, 0.06315789, 0.06842105, 0.07368421,\n",
       "       0.07894737, 0.08421053, 0.08947368, 0.09473684, 0.1       ]),\n",
       "                                        'loss': ['deviance', 'exponential'],\n",
       "                                        'max_depth': array([1, 2, 3, 4]),\n",
       "                                        'n_estimators': array([200, 250, 300, 350, 400, 450, 500])},\n",
       "                   scoring='roc_auc')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_space_gc =  {'loss':['deviance','exponential'], 'n_estimators': np.arange(200,501,50),\n",
    "             'max_depth':np.arange(1,5), 'learning_rate': np.linspace(0,.1,20)\n",
    "                }\n",
    "              \n",
    "              \n",
    "rnd_srch_gc = RandomizedSearchCV(gc, param_space_gc, n_iter=30, \n",
    "                                 cv=kfold, scoring=\"roc_auc\",\n",
    "                                 verbose=0\n",
    "                                ) \n",
    "\n",
    "                                 \n",
    "rnd_srch_gc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2a91d4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 250, 'max_depth': 3, 'loss': 'exponential', 'learning_rate': 0.021052631578947368} \n",
      " 0.9135292717753452\n"
     ]
    }
   ],
   "source": [
    "print(rnd_srch_gc.best_params_,\"\\n\",rnd_srch_gc.best_score_) \n",
    "gcb = rnd_srch_gc.best_estimator_\n",
    "# {'n_estimators': 250, 'max_depth': 3, 'loss': 'exponential', 'learning_rate': 0.021052631578947368} 0.9136387434554974"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4bf6e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9135292717753452\n",
      "0.052317718075555554\n"
     ]
    }
   ],
   "source": [
    "score_gcb = cross_val_score(gcb,x_train,y_train,cv=kfold,scoring=\"roc_auc\")\n",
    "print(score_gcb.mean()) \n",
    "print(score_gcb.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358e439e",
   "metadata": {},
   "source": [
    "Not bad, and not great! This is squarely at about the 60th percentile of all participants above the sample benchmark, while our Random Forest Classifier is at about the 94th percentile. \n",
    "\n",
    "\n",
    "We should want to experiment with the Random Forest Classifier more, in order to achieve the best possible score, given the noise in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23ad93e",
   "metadata": {},
   "source": [
    "Some discussion: \n",
    "\n",
    "Observing the variances of the Neural Net and the Gradient Boosting Classifier, it seems that both might benefit from a bit of bagging themselves. My suspicion is the Gradient Boosting Classifier would be more likely to benefit from this-- potentially making it competitive with the Random Forest Classifier-- while the Neural Net would directly trade off it's variance with bias.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
